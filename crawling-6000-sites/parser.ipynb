{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# multiprocessing\n",
    "from multiprocessing.pool import Pool\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = pd.read_csv('../datasets/domain.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lang_new(url):\n",
    "    '''\n",
    "    Функция \n",
    "    - принимает адрес домена\n",
    "    - подставляет к нему http:// или https://\n",
    "    - возвращает информацию о языке сайта указанном в атрибуте lang тега html, если такой есть\n",
    "    - если возникает какая-то ошибка, то возвращает имя данной ошибки \n",
    "    '''\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'}\n",
    "    \n",
    "    try:\n",
    "        html = requests.get('http://'+ str(url), timeout=30, headers=headers).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        lang = soup.html['lang']\n",
    "        return lang\n",
    "\n",
    "    # обработка ошибки с отсутствием доступа по http\n",
    "    except requests.exceptions.InvalidURL:\n",
    "        html = requests.get('https://'+ str(url), timeout=5, headers=headers).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        lang = soup.html['lang']\n",
    "        return lang\n",
    "\n",
    "    # все остальные ошибки\n",
    "    except Exception as exception:\n",
    "        return type(exception).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c9cd7aa14e4468bab2481b0ed08b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6609.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Запуск поиска языка в многопоточном режиме\n",
    "with ThreadPool(processes=100) as p:\n",
    "    domain['lang'] = tqdm(p.imap(find_lang_new, domain['domain']), total=len(domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как парсер был не самым идеальным и собрать 100% данных не получилось, то придется поработать руками прежде чем переходить к непосредственному анализу и выводам. Так как перед сохранением в файл не было никаких подготовительных процедур, то проведем их сейчас."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain['lang'] = domain['lang'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка ошибок\n",
    "Глобально все ошибки возникшие при сборе данных можно поделить на две части: \n",
    "- пустые значения - с сайтом удалось связаться, найти тег `html`, найти атрибут `lang`. Но вот информации в данном атрибуте не оказалось, было пусто. \n",
    "- `keyerror`, `connectionerror`,  `typeerror`, `connecttimeout`, `sslerror`,  `readtimeout`,  `toomanyredirects` -  какая-то причина которая помешала или связаться с сайтом, или забрать нужную информацию. Стоит отметить, что в большинстве случаев основная причина - динамическое формирование контента на сайте и отсутствие опыта по парсингу таких сайтов. \n",
    "\n",
    "Попробуем восстановить язык сайта исходя из его домена. Есть предположение, что сайты с доменом `fr`  будут содержать контент на французском. А вот домен `jp` намекает, что контент будет на японском. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка пропусков (NaN)\n",
    "domain.loc[domain['lang']=='', 'lang'] = 'no_lang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['com', 'jp', 'fr', 'ie', 'net', 'ca', 'org', 'uk', 'de', 'se',\n",
       "       'ch', 'be', 'life', 'nrw', 'co', 'online', 'nl', 'ms', 'dk', 'no',\n",
       "       'ru', 'info', 'site', 'coop', 'biz', 'nz', 'au', 'us', 'tv', 'fm',\n",
       "       'eu', 'at', 'network', 'guide', 'it', 'gov', 'studio', 'xyz',\n",
       "       'news', 'za', 'bm', 'pl', 'hr', 'tokyo', 'style', 'pro', 'cc',\n",
       "       'cafe', 'p1ai', 'bz', 'blog', 'club', 'mobi', 'ro', 'me', 'ir',\n",
       "       'su', 'ua', 'edu', 'in', 'social', 'my'], dtype=object)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выводим в новую метрику запись после последней точки в названии домена (отсекаем поддомены)\n",
    "domain['after_dot'] = domain['domain'].str.extract(r'.([\\w]+$)', expand=True)\n",
    "domain['after_dot'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список доменов которые не позволяют однозначно сделать вывод о стране которая предпочтет их использовать\n",
    "domain_no_country = ['com', 'net', 'org', 'life', 'online', 'info', 'site', 'coop', 'biz', 'tv', 'fm',\n",
    "                    'network', 'guide', 'gov', 'studio', 'xyz', 'news', 'style', 'pro', 'cafe', 'blog',\n",
    "                    'club', 'mobi', 'edu', 'social']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список ошибок которые получились при сборе данных \n",
    "errors = ['keyerror', 'connectionerror', 'no_lang', 'typeerror', 'typeerror', 'sslerror', 'connecttimeout',\n",
    "         'readtimeout', 'toomanyredirects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего доменов: 6609 \n",
      "Доменов с ошибками: 1244\n"
     ]
    }
   ],
   "source": [
    "print('Всего доменов: {}'.format(len(domain)),\n",
    "     '\\nДоменов с ошибками: {}'.format(len(domain[domain['lang'].isin(errors)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибок почти 18%. Как-то много, эх. Произведем замену ошибок на домен последнего уровня и оценим результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain.loc[(domain['lang']=='keyerror')&(~domain['after_dot'].isin(domain_no_country)),'lang'] = domain['after_dot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка языков\n",
    "Посмотрим, что получается по языкам которые удалось собрать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'ja', 'fr', 'de', 'ca', 'sv', 'se', 'ch', 'nrw', 'nl', 'ms',\n",
       "       'be', 'da', 'no', 'ru', 'nz', 'at', 'it', 'pl', 'au', 'es', 'eu',\n",
       "       'ro', 'dk', 'co', 'me', 'pt', 'bg', 'id', 'nb', 'ir', 'ar', 'su',\n",
       "       'in', 'he'], dtype=object)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain[~domain['lang'].isin(errors)]['lang'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- есть дубликаты, например `ru` и `ru-ru`. \n",
    "- есть сайты где атрибут `lang` имел сразу два языка.   \n",
    "\n",
    "Исправим эти разночтения и приведем все к единому типу записи. Сделаем допущение, что если на сайта было указано два языка, то первый считается основным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Промежуточная метрика с первым языком\n",
    "domain['new_lang'] = domain['lang'].str.extract(r'(..)-')\n",
    "\n",
    "# Меняем двойные языки на первые\n",
    "domain.loc[domain['new_lang'].notnull(), 'lang'] = domain['new_lang']\n",
    "\n",
    "# Удаляем промежуточную метрику\n",
    "domain.drop(['new_lang'], axis=1, inplace=True)\n",
    "\n",
    "# Чистим мелкие артефакты\n",
    "domain.loc[domain['lang']==' da', 'lang'] = 'da'\n",
    "domain.loc[domain['lang']=='de_de', 'lang'] = 'de'\n",
    "domain.loc[domain['lang']=='en_us', 'lang'] = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'ja', 'fr', 'de', 'ca', 'sv', 'se', 'ch', 'nrw', 'nl', 'ms',\n",
       "       'be', 'da', 'no', 'ru', 'nz', 'at', 'it', 'pl', 'au', 'es', 'eu',\n",
       "       'ro', 'dk', 'co', 'me', 'pt', 'bg', 'id', 'nb', 'ir', 'ar', 'su',\n",
       "       'in', 'he'], dtype=object)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain[~domain['lang'].isin(errors)]['lang'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало лучше, но еще есть что поправить. Так как в рамках данного анализа нет цели различать между собой разные типы английский языков, то объединим их все в единую группу `en`. Заодно исправим помехи от заполнения пропусков доменами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain.loc[domain['lang'].isin(['uk', 'us']), 'lang'] = 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще поправим кириллические домены и отнесем их к языку `ru`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain.loc[domain['lang'].isin(['p1ai']), 'lang'] = 'ru'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А `tokyo` заменим на уже привычный `jp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain.loc[domain['lang'].isin(['tokyo']), 'lang'] = 'ja'\n",
    "domain.loc[domain['lang'].isin(['jp']), 'lang'] = 'ja'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "Похоже, что теперь все готово для подведения итогов. Посмотрим как распределяются языки по сайтам изучаемой категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего было найдено языков: 35\n"
     ]
    }
   ],
   "source": [
    "print('Всего было найдено языков: {}'.format(len(domain[~domain['lang'].isin(errors)]['lang'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Думаю, что можно смело ограничиться первыми десятью языками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    4129\n",
       "ja     462\n",
       "fr     387\n",
       "de     195\n",
       "ru      49\n",
       "ca      44\n",
       "nl      17\n",
       "da      16\n",
       "sv       9\n",
       "be       8\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain[~domain['lang'].isin(errors)]['lang'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Абсолютное лидерство английского языка не стало каким-то откровением. Данный результат был вполне ожидаем. Важнее было понять какие языки будут идти сразу за ним. И здесь лидерами стали `ja`, `fr`, `de`.  Стоит отметить, что в данных SimilarWeb совершенно не было сайтов из Китая. Скорее всего это объясняется всем известной изолированностью китайского интернета. \n",
    "- Необходимо освоить парсинг сайтов с динамической генерацией контента, пригодится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним данные для потомков\n",
    "domain.to_csv('../datasets/domain_lang_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
